{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89caab1b-a64c-4038-858f-b714d429a114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cb5a62a-63ab-4c0b-b531-a67b9e1f5e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup hyperparameters\n",
    "BATCH_SIZE = 32 # good for your health: https://twitter.com/ylecun/status/989610208497360896\n",
    "EPOCHS = 10 # only run for a short period of time... we don't have all day\n",
    "DATASET_NAME = \"cifar10\" # change this to try other image datasets from TensorFlow Datasets\n",
    "DEVICE = \"Google Colab (K80 GPU)\" # change this depending on where you're runing the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f4bb7ec-cc83-45a2-82e2-0f5996a877e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions already downloaded, skipping redownload.\n"
     ]
    }
   ],
   "source": [
    "# Get helper functions\n",
    "import os\n",
    "import requests\n",
    "\n",
    "if not os.path.exists(\"helper_functions.py\"):\n",
    "  print(\"Downloading helper functions...\")\n",
    "  r = requests.get(\"https://raw.githubusercontent.com/mrdbourke/m1-machine-learning-test/main/helper_functions.py\")\n",
    "  print(\"Writing helper functions to file...\")\n",
    "  open(\"helper_functions.py\", \"wb\").write(r.content)\n",
    "else:\n",
    "  print(\"Helper functions already downloaded, skipping redownload.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6daa9f8f-44b4-4bc8-9bed-b218fd7e080a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "# Check TensorFlow version\n",
    "import tensorflow as tf\n",
    "print(tf.__version__) # should be 2.5.0+\n",
    "\n",
    "# Get TensorFlow Datasets\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Get data science libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from timeit import default_timer as timer \n",
    "from helper_functions import print_train_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c5e892d-d726-4f05-ab68-3aadb192a105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from tf.keras.datasets\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48dcd83f-6ddd-4ec3-aac8-f8b53b329cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6442bbf2-85c0-406f-aa8b-241a364c4add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Image shape: (32, 32, 3)\n",
      "  Image dtype: float64\n",
      "  Target class from Food101: 6\n",
      "  Class name (str form): frog\n",
      "        \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect image\n",
    "image = train_images[0]\n",
    "label = int(train_labels[0])\n",
    "\n",
    "print(f\"\"\"\n",
    "  Image shape: {image.shape}\n",
    "  Image dtype: {image.dtype}\n",
    "  Target class from Food101: {label}\n",
    "  Class name (str form): {class_names[label]}\n",
    "        \"\"\")\n",
    "plt.imshow(image)\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dced3b8d-bfa1-4c8b-b84d-9f6fea6a9a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 06:45:05.412725: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-11-09 06:45:05.412745: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-11-09 06:45:05.412748: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-11-09 06:45:05.412801: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-09 06:45:05.412824: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.uint8, name=None))>,\n",
       " <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.uint8, name=None))>,\n",
       " 1563,\n",
       " 313)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create datasets \n",
    "train_data = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "\n",
    "# Make datasets faster\n",
    "train_data = train_data.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_data = test_data.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_data, test_data, len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a08562ef-ca34-41d8-a154-3ce6752f12d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 06:45:07.106338: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 1.7388 - accuracy: 0.3668"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 06:45:23.721940: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.7388 - accuracy: 0.3668 - val_loss: 1.6148 - val_accuracy: 0.4255\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.4401 - accuracy: 0.4816 - val_loss: 1.4663 - val_accuracy: 0.4827\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 16s 11ms/step - loss: 1.3378 - accuracy: 0.5228 - val_loss: 1.3162 - val_accuracy: 0.5341\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.2651 - accuracy: 0.5514 - val_loss: 1.2328 - val_accuracy: 0.5667\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.2154 - accuracy: 0.5722 - val_loss: 1.1847 - val_accuracy: 0.5825\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.1774 - accuracy: 0.5865 - val_loss: 1.1509 - val_accuracy: 0.5953\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.1467 - accuracy: 0.5979 - val_loss: 1.1289 - val_accuracy: 0.6030\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.1241 - accuracy: 0.6064 - val_loss: 1.1143 - val_accuracy: 0.6073\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.1062 - accuracy: 0.6122 - val_loss: 1.1005 - val_accuracy: 0.6117\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.0903 - accuracy: 0.6182 - val_loss: 1.0912 - val_accuracy: 0.6128\n",
      "\n",
      "Train time on Google Colab (K80 GPU): 172.578 seconds\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Start time\n",
    "start_time = timer()\n",
    "\n",
    "# Create a CNN model (same as Tiny VGG - https://poloclub.github.io/cnn-explainer/)\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(filters=10, \n",
    "                         kernel_size=3, # can also be (3, 3)\n",
    "                         activation=\"relu\", \n",
    "                         input_shape=(32, 32, 3)), # first layer specifies input shape (height, width, colour channels)\n",
    "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
    "  tf.keras.layers.MaxPool2D(pool_size=2, # pool_size can also be (2, 2)\n",
    "                            padding=\"valid\"), # padding can also be 'same'\n",
    "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
    "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"), # activation='relu' == tf.keras.layers.Activations(tf.nn.relu)\n",
    "  tf.keras.layers.MaxPool2D(2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(10, activation=\"softmax\") # multi-class activation output\n",
    "], name=\"TinyVGG\")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", # since labels aren't one-hot, use sparse_categorical_crossentropy\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit model \n",
    "history = model.fit(train_data,\n",
    "                    epochs=EPOCHS,\n",
    "                    steps_per_epoch=len(train_data),\n",
    "                    validation_data=test_data,\n",
    "                    validation_steps=len(test_data))\n",
    "\n",
    "# Track time \n",
    "end_time = timer()\n",
    "train_time = print_train_time(start_time, \n",
    "                              end_time, \n",
    "                              device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ca8734c-9138-4861-9e1c-d3920f3c5592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_train_samples</th>\n",
       "      <th>num_test_samples</th>\n",
       "      <th>total_train_time</th>\n",
       "      <th>time_per_epoch</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google Colab (K80 GPU)</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>50016</td>\n",
       "      <td>10016</td>\n",
       "      <td>172.578</td>\n",
       "      <td>17.258</td>\n",
       "      <td>TinyVGG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   device dataset_name  epochs  batch_size  num_train_samples  \\\n",
       "0  Google Colab (K80 GPU)      cifar10      10          32              50016   \n",
       "\n",
       "   num_test_samples  total_train_time  time_per_epoch    model  \n",
       "0             10016           172.578          17.258  TinyVGG  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {\n",
    "    \"device\": DEVICE,\n",
    "    \"dataset_name\": DATASET_NAME,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"num_train_samples\": len(train_data)*BATCH_SIZE,\n",
    "    \"num_test_samples\": len(test_data)*BATCH_SIZE,\n",
    "    \"total_train_time\": round(train_time, 3),\n",
    "    \"time_per_epoch\": round(train_time/EPOCHS, 3),\n",
    "    \"model\": model.name\n",
    "    }\n",
    "results_df = pd.DataFrame(results, index=[0])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2b7307b-13af-4cf7-b063-a43dac5408a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write CSV to file\n",
    "if not os.path.exists(\"results/\"):\n",
    "  os.makedirs(\"results/\")\n",
    "\n",
    "results_df.to_csv(f\"results/{DEVICE}_{DATASET_NAME}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85ae9ed-dc3c-4182-9756-b624c868c366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
